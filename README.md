# Classification MNIST

**Auteurs :** Youssef Bouamama & Amine Itji

Ce projet compare l'efficacitÃ© de diffÃ©rentes architectures de rÃ©seaux de neurones (Deep Learning) sur le dataset de chiffres manuscrits **MNIST**.

Il a Ã©tÃ© rÃ©alisÃ© avec **PyTorch** et met en Ã©vidence la supÃ©rioritÃ© des rÃ©seaux convolutifs pour le traitement d'images par rapport aux architectures basÃ©es uniquement sur des **couches pleinement connectÃ©es**.

## Objectifs

* ImplÃ©menter des rÃ©seaux de neurones (Shallow, Deep, CNN).
* Comparer l'impact de la **profondeur** et de la **structure** (Convolutions vs Fully Connected).
* Optimiser les hyperparamÃ¨tres (Learning rate, Batch size, Nombre d'Ã©poques, Taille des couches, Profondeur) pour chaque modÃ¨le.

## Architectures ImplÃ©mentÃ©es

Le code source dans `src/` propose trois modÃ¨les distincts :

### 1. Shallow Network
* **Type :** MLP (Multi-Layer Perceptron)
* **Structure :** Une seule **couche pleinement connectÃ©e** cachÃ©e.
* **RÃ´le :** Sert de rÃ©fÃ©rence (baseline). Montre qu'une simple projection linÃ©aire suivie d'une non-linÃ©aritÃ© capture dÃ©jÃ  l'essentiel.

### 2. Deep Network (RÃ©seau Profond)
* **Type :** MLP Profond
* **Structure :** Empilement de plusieurs **couches pleinement connectÃ©es**.
* **Observation :** L'ajout de profondeur en "Fully Connected" n'amÃ©liore pas significativement la performance sur MNIST et augmente le risque de sur-apprentissage.

### 3. CNN (LeNet-5)
* **Type :** Convolutional Neural Network
* **Structure :** Architecture hybride : Extraction de features (Convolutions) $\to$ Classification (**Couches pleinement connectÃ©es**).
* **Avantage :** Exploite la structure spatiale de l'image. Atteint une meilleure prÃ©cision avec **3x moins de paramÃ¨tres** que les rÃ©seaux pleinement connectÃ©s.

## SynthÃ¨se des RÃ©sultats

### ðŸ“Š SynthÃ¨se des RÃ©sultats

Nos expÃ©riences ont permis d'obtenir les prÃ©cisions suivantes sur le jeu de test :

| ModÃ¨le | Configuration Optimale | PrÃ©cision (Test) | ParamÃ¨tres | Conclusion |
| :--- | :--- | :---: | :---: | :--- |
| **Shallow** | Hidden=256, LR=0.001, Batch=32 | 98.14% | ~200k | Efficace mais limitÃ© par l'aplatissement. |
| **Deep** | [256â†’128â†’64], LR=0.001, Batch=32 | 98.03% | ~300k | Pas de gain via la profondeur. |
| **CNN** | LeNet-5, LR=0.001, Batch=32 | **98.99%** | **~60k** | **Excellent.** Quasi aucun overfitting. |


## Project Structure

```
projet_M2_deep_learning/
â”œâ”€â”€ dataset/
â”‚   â””â”€â”€ mnist.pkl.gz
â”œâ”€â”€ doc/
â”‚   â””â”€â”€ doc.md
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ main.py
â”‚   â”œâ”€â”€ perceptron_pytorch.py
â”‚   â”œâ”€â”€ perceptron_pytorch_data_auto_layer_optim.py
â”‚   â”œâ”€â”€ shallow_network.py
â”‚   â”œâ”€â”€ deep_network.py
â”‚   â””â”€â”€ cnn_network.py
â”œâ”€â”€ .gitignore
â”œâ”€â”€ projet.pdf
â”œâ”€â”€ README.md
â””â”€â”€ requirements.txt
```

## Installation

### 1. Setup Environment

```bash
python3 -m venv env
source env/bin/activate        # Linux/Mac
# or
env\Scripts\activate           # Windows
```

### 2. Install Dependencies

```bash
pip install -r requirements.txt
```

### 3. Verify Installation

```bash
python -c "import torch; print('PyTorch OK')"
```

## Run

### Interactive Menu

```bash
cd src/
python main.py
```

### Individual Scripts

```bash
# Part 1 - Perceptron
python perceptron_pytorch.py

# Part 2 - Shallow Network
python shallow_network.py

# Part 3 - Deep Network
python deep_network.py

# Part 4 - CNN
python cnn_network.py
```

### Generate PDF 

```bash
pandoc RAPPORT.md -o RAPPORT.pdf --css style.css --pdf-engine=weasyprint --metadata title=""
```